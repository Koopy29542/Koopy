import random
import numpy as np

from utils import compute_interval_lengths, evaluate_prediction_set


class AdaptiveConformalPredictionModule:
    """
    See Gibbs & Candes, 2021, or Zaffran et al., 2022.
    """

    def __init__(self,
                 target_miscoverage_level,
                 step_size,
                 n_scores,
                 score_functions,
                 max_interval_lengths,
                 calibration_set_size,
                 offline_calibration_set_y
                 ):
        self._n_scores = n_scores
        self._score_functions = score_functions

        self._alpha = target_miscoverage_level

        # effective miscoverage level alpha_t
        # initialization: alpha_0 := alpha
        self._alpha_t = target_miscoverage_level * np.ones(self._n_scores)

        self._alpha_t_history = [np.copy(self._alpha_t)]

        self._coverage_history = []

        # step size parameter
        # gamma = 0 corresponds to the standard split conformal prediction
        self._gamma = step_size
        self._max_interval_len = max_interval_lengths

        self._interval_len = max_interval_lengths * np.ones(self._n_scores)
        self._interval_len_history = [np.copy(self._interval_len)]

        self._offline_calibration_set_y = offline_calibration_set_y

        # want to avoid sampling duplicate (f(x), y) data
        self._calibration_set_size = calibration_set_size
        assert len(self._offline_calibration_set_y) >= calibration_set_size

        self._online_calibration_set_y = []

        self._step = 0

    def update(self, y_model, y):
        self._update_interval_lengths()
        self._update_miscoverage_levels(y_model, y)
        self._online_calibration_set_y.append((y_model, y))
        self._step += 1

    def _update_miscoverage_levels(self, y_model, y):
        correct = evaluate_prediction_set(
            test_set_y=[(y_model, y)],
            score_functions=self._score_functions,
            interval_len=self._interval_len
        )
        assert correct.shape == (1, self._n_scores)
        correct = np.squeeze(correct)
        self._coverage_history.append(correct)
        self._alpha_t += self._gamma * (self._alpha - 1. + correct)
        self._alpha_t_history.append(np.copy(self._alpha_t))
        return

    def _update_interval_lengths(self):
        """
        :param calibration_set_y:
        :param y_model: prediction generated by our model given x_t
        :param y: observation y_t at time t
        :return:
        """
        n_offline_samples = self._calibration_set_size - self._step

        offline_calibration_set_y = []
        for _ in range(n_offline_samples):
            offline_calibration_set_y.append(random.choice(self._offline_calibration_set_y))

        # calibration set construction: random subset of offline data + online data
        calibration_set_y = offline_calibration_set_y + self._online_calibration_set_y

        interval_len = compute_interval_lengths(
            self._alpha_t,
            calibration_set_y,
            self._n_scores,
            self._score_functions,
            self._max_interval_len
        )
        self._interval_len = interval_len
        self._interval_len_history.append(np.copy(self._interval_len))

        return

    def get_effective_miscoverage_level_history(self):
        return np.array(self._alpha_t_history)

    def get_interval_length_history(self):
        return np.copy(self._interval_len_history)

    def get_interval_lengths(self):
        return np.copy(self._interval_len)

    def get_cumulative_coverage(self):
        return np.cumsum(np.array(self._coverage_history), axis=0) / np.expand_dims(np.arange(1, self._step+1), axis=1)

    def get_final_coverage(self):
        return np.sum(self._coverage_history, axis=0) / self._step
